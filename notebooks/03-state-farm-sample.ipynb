{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import fastai\n",
    "from fastai.fautils import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data_path = os.path.expanduser('~/data/state-farm/')\n",
    "samp_data_path = os.path.expanduser('~/data/sample-state-farm/')\n",
    "data_path = samp_data_path\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overview\n",
    "\n",
    "This notebook shows a lot of exploratory work with the State Farm kaggle challenge.  The biggest takeaways are:\n",
    "\n",
    "1. Find the smallest sample size that produces consistent results\n",
    "1. Start with very small models and quickly work up in complexity, till you're overfitting\n",
    "1. Selecting the initial training rate, and adjusting it through training is really important\n",
    "1. Get familiar with data augmentation, but remember you can't precompute your convolutional layers\n",
    "1. Dropout is super important, but the value is dependent on your training set size, so you need to relearn it after you finish with the sample set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regenerate sample dataset\n",
    "\n",
    "**TODO:** Regenerate initial state farm dataset so drivers are split between training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075', 'p081']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.expanduser('~/data/state-farm/driver_imgs_list.csv'))\n",
    "subjects = df.subject.unique().tolist()\n",
    "subjects.sort()\n",
    "print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/state-farm\n"
     ]
    }
   ],
   "source": [
    "# %cd ~/data/state-farm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %rm -rf ../sample-state-farm/\n",
    "\n",
    "# %mkdir ../sample-state-farm\n",
    "# %mkdir ../sample-state-farm/train\n",
    "# %mkdir ../sample-state-farm/valid\n",
    "# %mkdir ../sample-state-farm/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for dd in glob('train/c?'):\n",
    "#     d = os.path.split(dd)[-1]\n",
    "#     os.mkdir('../sample-state-farm/train/'+d)\n",
    "#     os.mkdir('../sample-state-farm/valid/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "\n",
    "# g = glob('c?/*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(1500):\n",
    "#     copyfile(shuf[i], '../../sample-state-farm/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/state-farm/valid\n"
     ]
    }
   ],
   "source": [
    "# %cd ../valid/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from shutil import copyfile\n",
    "\n",
    "# g = glob('c?/*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(1000):\n",
    "#     copyfile(shuf[i], '../../sample-state-farm/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/fastai-deep-learning/notebooks\n"
     ]
    }
   ],
   "source": [
    "# %cd ~/projects/fastai-deep-learning/notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "t_batches = get_batches(data_path + 'train', batch_size=batch_size)\n",
    "v_batches = get_batches(data_path + 'valid', batch_size=2*batch_size, shuffle=False)\n",
    "\n",
    "(\n",
    "    val_classes, trn_classes, \n",
    "    val_labels, trn_labels, \n",
    "    val_filenames, filenames,\n",
    "    test_filename\n",
    ") = get_classes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "\n",
    "    # starting with BatchNormalization saves us from having to normalize our input manually\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3, 224, 224)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        Adam(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNorma (None, 3, 224, 224)   12          batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 150528)        0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            1505290     flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,505,302\n",
      "Trainable params: 1,505,296\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/1\n",
      "1500/1500 [==============================] - 42s - loss: 12.8955 - acc: 0.1520 - val_loss: 13.5688 - val_acc: 0.1560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80bab54990>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = get_lin_model()\n",
    "lm.summary()\n",
    "\n",
    "lm.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=1, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(lm.predict_generator(t_batches, t_batches.nb_sample)[:10],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is entirely predicting 2 of the classes.  Not very useful.  Lower the learning rate and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 39s - loss: 2.4683 - acc: 0.1660 - val_loss: 3.9722 - val_acc: 0.1870\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 31s - loss: 1.7675 - acc: 0.4147 - val_loss: 2.4385 - val_acc: 0.3190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f809a9bea50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = get_lin_model()\n",
    "\n",
    "lm.optimizer.lr.set_value(1e-5)\n",
    "lm.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=2, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 40s - loss: 1.3893 - acc: 0.6007 - val_loss: 1.8993 - val_acc: 0.3790\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 29s - loss: 1.1313 - acc: 0.6720 - val_loss: 1.4696 - val_acc: 0.5150\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.9877 - acc: 0.7447 - val_loss: 1.1339 - val_acc: 0.6470\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 31s - loss: 0.8400 - acc: 0.8093 - val_loss: 1.0171 - val_acc: 0.7040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80b88fbd50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.optimizer.lr.set_value(1e-3)\n",
    "lm.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=4,\n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation accuracy of 0.64 -- almost too good to be true, and definitely better than chance.\n",
    "\n",
    "Now lets make sure validation set is large enough to ensure a stable accuracy metric across runs, so we aren't making the wrong generalization about the results we're observing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 10 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.02,  0.7 ],\n",
       "       [ 1.03,  0.7 ],\n",
       "       [ 1.01,  0.7 ],\n",
       "       [ 1.02,  0.71],\n",
       "       [ 1.  ,  0.7 ],\n",
       "       [ 1.04,  0.69],\n",
       "       [ 1.  ,  0.71],\n",
       "       [ 1.04,  0.7 ],\n",
       "       [ 1.02,  0.7 ],\n",
       "       [ 1.04,  0.69]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_batches = get_batches(data_path+'valid', batch_size=2*batch_size)\n",
    "val_res = [lm.evaluate_generator(r_batches, r_batches.nb_sample) for i in range(10)]\n",
    "np.round(val_res, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consisent results.  Accuracy increases larger than than 2% can't be attributed to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularized linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reglin_model():\n",
    "\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3, 224, 224)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax', W_regularizer=l2(0.01))\n",
    "    ])\n",
    "    model.compile(\n",
    "        Adam(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 38s - loss: 2.5457 - acc: 0.1920 - val_loss: 3.7482 - val_acc: 0.2260\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 29s - loss: 1.9201 - acc: 0.4160 - val_loss: 2.4799 - val_acc: 0.3470\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 38s - loss: 1.5539 - acc: 0.5967 - val_loss: 1.9994 - val_acc: 0.4250\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 30s - loss: 1.3283 - acc: 0.6793 - val_loss: 1.4563 - val_acc: 0.5930\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 30s - loss: 1.1911 - acc: 0.7513 - val_loss: 1.4038 - val_acc: 0.5940\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 30s - loss: 1.0617 - acc: 0.8040 - val_loss: 1.2790 - val_acc: 0.6680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80b324a350>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlm = get_reglin_model()\n",
    "\n",
    "rlm.optimizer.lr.set_value(1e-5)\n",
    "rlm.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=2, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")\n",
    "\n",
    "rlm.optimizer.lr.set_value(1e-3)\n",
    "rlm.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=4, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single linear model with regularization is getting 64% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3, 224, 224)),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        Adam(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_4 (BatchNorma (None, 3, 224, 224)   12          batchnormalization_input_4[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 150528)        0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 100)           15052900    flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_5 (BatchNorma (None, 100)           400         dense_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            1010        batchnormalization_5[0][0]       \n",
      "====================================================================================================\n",
      "Total params: 15,054,322\n",
      "Trainable params: 15,054,116\n",
      "Non-trainable params: 206\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc = get_fc_model()\n",
    "fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 41s - loss: 2.0159 - acc: 0.3413 - val_loss: 8.0656 - val_acc: 0.1280\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 30s - loss: 1.1137 - acc: 0.6773 - val_loss: 3.1675 - val_acc: 0.3120\n",
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 40s - loss: 0.6243 - acc: 0.8647 - val_loss: 1.4680 - val_acc: 0.5360\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 29s - loss: 0.4106 - acc: 0.9300 - val_loss: 0.8222 - val_acc: 0.7380\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 29s - loss: 0.2662 - acc: 0.9693 - val_loss: 0.6014 - val_acc: 0.8360\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 30s - loss: 0.1932 - acc: 0.9840 - val_loss: 0.5460 - val_acc: 0.8690\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 32s - loss: 0.1286 - acc: 0.9947 - val_loss: 0.4677 - val_acc: 0.8910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f80ac03cc10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.optimizer.lr.set_value(1e-5)\n",
    "fc.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=2, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")\n",
    "\n",
    "fc.optimizer.lr.set_value(0.01)\n",
    "fc.fit_generator(\n",
    "    t_batches, \n",
    "    t_batches.nb_sample, \n",
    "    nb_epoch=5, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, 89% accuracy with 2 fully connected layers.  Why is this so much better than the sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conv_model(t_batches=t_batches, v_batches=v_batches, train=True):\n",
    "\n",
    "    model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3, 224, 224)),\n",
    "        Convolution2D(32,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Convolution2D(64,3,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((3,3)),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        Adam(), \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    if not train:\n",
    "        return model\n",
    "    \n",
    "    model.optimizer.lr.set_value(1e-4)\n",
    "    h = model.fit_generator(\n",
    "        t_batches, \n",
    "        t_batches.nb_sample, \n",
    "        nb_epoch=2, \n",
    "        validation_data=v_batches, \n",
    "        nb_val_samples=v_batches.nb_sample\n",
    "    )\n",
    "\n",
    "    model.optimizer.lr.set_value(1e-3)\n",
    "    h = model.fit_generator(\n",
    "        t_batches, \n",
    "        t_batches.nb_sample, \n",
    "        nb_epoch=4, \n",
    "        validation_data=v_batches, \n",
    "        nb_val_samples=v_batches.nb_sample\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 46s - loss: 1.5421 - acc: 0.5367 - val_loss: 1.8506 - val_acc: 0.3610\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 31s - loss: 0.4056 - acc: 0.9153 - val_loss: 1.5868 - val_acc: 0.5370\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 41s - loss: 0.3371 - acc: 0.9267 - val_loss: 1.3590 - val_acc: 0.5930\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 32s - loss: 0.0787 - acc: 0.9900 - val_loss: 1.6165 - val_acc: 0.4890\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 31s - loss: 0.0212 - acc: 0.9980 - val_loss: 1.9551 - val_acc: 0.3700\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.0089 - acc: 0.9993 - val_loss: 2.1163 - val_acc: 0.3420\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_39 (BatchNorm (None, 3, 224, 224)   12          batchnormalization_input_14[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 32, 222, 222)  896         batchnormalization_39[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_40 (BatchNorm (None, 32, 222, 222)  128         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_17 (MaxPooling2D)   (None, 32, 74, 74)    0           batchnormalization_40[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 64, 72, 72)    18496       maxpooling2d_17[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_41 (BatchNorm (None, 64, 72, 72)    256         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_18 (MaxPooling2D)   (None, 64, 24, 24)    0           batchnormalization_41[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 36864)         0           maxpooling2d_18[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_23 (Dense)                 (None, 200)           7373000     flatten_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_42 (BatchNorm (None, 200)           800         dense_23[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_24 (Dense)                 (None, 10)            2010        batchnormalization_42[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 7,395,598\n",
      "Trainable params: 7,395,000\n",
      "Non-trainable params: 598\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cm = get_conv_model()\n",
    "cm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very rapidly learning the training data and failing to generalize to the validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 39s - loss: 2.1456 - acc: 0.3387 - val_loss: 2.6849 - val_acc: 0.2140\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 30s - loss: 1.1573 - acc: 0.6500 - val_loss: 2.0351 - val_acc: 0.2800\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 39s - loss: 0.7907 - acc: 0.7640 - val_loss: 2.0810 - val_acc: 0.2800\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 32s - loss: 0.5969 - acc: 0.8307 - val_loss: 2.0220 - val_acc: 0.2950\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 29s - loss: 0.4668 - acc: 0.8773 - val_loss: 1.9915 - val_acc: 0.3470\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 32s - loss: 0.3911 - acc: 0.9000 - val_loss: 1.9675 - val_acc: 0.3350\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "batches = get_batches(data_path+'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 39s - loss: 1.9171 - acc: 0.3907 - val_loss: 2.0805 - val_acc: 0.3340\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 30s - loss: 0.8405 - acc: 0.7560 - val_loss: 1.8873 - val_acc: 0.2770\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 40s - loss: 0.5072 - acc: 0.8707 - val_loss: 2.0501 - val_acc: 0.3230\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 33s - loss: 0.3236 - acc: 0.9287 - val_loss: 2.1987 - val_acc: 0.3110\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.2141 - acc: 0.9493 - val_loss: 2.2473 - val_acc: 0.3120\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.1854 - acc: 0.9640 - val_loss: 2.2111 - val_acc: 0.2910\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(height_shift_range=0.05)\n",
    "batches = get_batches(data_path+'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 42s - loss: 1.6951 - acc: 0.4773 - val_loss: 2.3676 - val_acc: 0.2660\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 30s - loss: 0.5238 - acc: 0.8653 - val_loss: 1.9156 - val_acc: 0.2480\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 42s - loss: 0.2121 - acc: 0.9653 - val_loss: 1.9712 - val_acc: 0.2690\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.1151 - acc: 0.9873 - val_loss: 2.0243 - val_acc: 0.2400\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.0649 - acc: 0.9933 - val_loss: 1.8606 - val_acc: 0.2980\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 32s - loss: 0.0448 - acc: 0.9967 - val_loss: 1.8760 - val_acc: 0.2940\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(shear_range=0.1)\n",
    "batches = get_batches(data_path+'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 40s - loss: 2.0496 - acc: 0.3507 - val_loss: 2.7200 - val_acc: 0.1260\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 29s - loss: 0.9951 - acc: 0.7033 - val_loss: 1.7754 - val_acc: 0.3620\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 40s - loss: 0.6304 - acc: 0.8287 - val_loss: 1.8712 - val_acc: 0.2820\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 30s - loss: 0.4445 - acc: 0.8853 - val_loss: 2.2688 - val_acc: 0.1590\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 33s - loss: 0.3587 - acc: 0.9013 - val_loss: 2.2709 - val_acc: 0.1470\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 29s - loss: 0.2510 - acc: 0.9433 - val_loss: 2.4715 - val_acc: 0.1220\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15)\n",
    "batches = get_batches(data_path+'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 40s - loss: 1.7166 - acc: 0.4893 - val_loss: 2.0138 - val_acc: 0.2930\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 31s - loss: 0.4397 - acc: 0.8980 - val_loss: 1.6513 - val_acc: 0.4190\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 42s - loss: 0.1346 - acc: 0.9853 - val_loss: 1.7306 - val_acc: 0.4240\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 35s - loss: 0.0641 - acc: 0.9973 - val_loss: 1.7484 - val_acc: 0.5030\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 35s - loss: 0.0341 - acc: 0.9993 - val_loss: 1.7369 - val_acc: 0.5350\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 35s - loss: 0.0229 - acc: 0.9987 - val_loss: 1.6780 - val_acc: 0.5760\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(channel_shift_range=20)\n",
    "batches = get_batches(data_path+'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 45s - loss: 2.5133 - acc: 0.2273 - val_loss: 2.9376 - val_acc: 0.1880\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 31s - loss: 1.8441 - acc: 0.3753 - val_loss: 2.0242 - val_acc: 0.2570\n",
      "<keras.callbacks.History object at 0x7f209c099550>\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 38s - loss: 1.8548 - acc: 0.4173 - val_loss: 2.3941 - val_acc: 0.2560\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 31s - loss: 1.4714 - acc: 0.5020 - val_loss: 2.2814 - val_acc: 0.2660\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 29s - loss: 1.1809 - acc: 0.6147 - val_loss: 2.4339 - val_acc: 0.2040\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 31s - loss: 1.0778 - acc: 0.6493 - val_loss: 2.4048 - val_acc: 0.2180\n",
      "<keras.callbacks.History object at 0x7f209b6c7690>\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=15,\n",
    "    channel_shift_range=20\n",
    ")\n",
    "batches = get_batches(data_path + 'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 37s - loss: 0.5271 - acc: 0.8527 - val_loss: 2.0215 - val_acc: 0.2700\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 27s - loss: 0.4013 - acc: 0.9033 - val_loss: 1.9464 - val_acc: 0.2810\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 28s - loss: 0.3007 - acc: 0.9413 - val_loss: 1.8280 - val_acc: 0.3030\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 28s - loss: 0.2313 - acc: 0.9620 - val_loss: 1.6918 - val_acc: 0.3320\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 29s - loss: 0.1789 - acc: 0.9727 - val_loss: 1.5590 - val_acc: 0.3680\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr.set_value(0.0001)\n",
    "model.fit_generator(\n",
    "    batches, batches.nb_sample, \n",
    "    nb_epoch=5, \n",
    "    validation_data=v_batches, nb_val_samples=v_batches.nb_sample)\n",
    "model.fit_generator(\n",
    "    batches, batches.nb_sample, \n",
    "    nb_epoch=25, \n",
    "    validation_data=v_batches, nb_val_samples=v_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 10 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16091745710372926, 0.95399999952316283]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf_batches = get_batches(os.path.expanduser('~/data/state-farm/') + 'valid', batch_size=2*batch_size, shuffle=False)\n",
    "model.evaluate_generator(vf_batches, vf_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_43 (BatchNorm (None, 3, 224, 224)   12          batchnormalization_input_15[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 32, 222, 222)  896         batchnormalization_43[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_44 (BatchNorm (None, 32, 222, 222)  128         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_19 (MaxPooling2D)   (None, 32, 74, 74)    0           batchnormalization_44[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 64, 72, 72)    18496       maxpooling2d_19[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_45 (BatchNorm (None, 64, 72, 72)    256         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_20 (MaxPooling2D)   (None, 64, 24, 24)    0           batchnormalization_45[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 36864)         0           maxpooling2d_20[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_25 (Dense)                 (None, 200)           7373000     flatten_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_46 (BatchNorm (None, 200)           800         dense_25[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_26 (Dense)                 (None, 10)            2010        batchnormalization_46[0][0]      \n",
      "====================================================================================================\n",
      "Total params: 7,395,598\n",
      "Trainable params: 7,395,000\n",
      "Non-trainable params: 598\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(data_path + 'state-farm-cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full training plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "1500/1500 [==============================] - 37s - loss: 2.5090 - acc: 0.2287 - val_loss: 2.7436 - val_acc: 0.1910\n",
      "Epoch 2/2\n",
      "1500/1500 [==============================] - 28s - loss: 1.7861 - acc: 0.3973 - val_loss: 2.2133 - val_acc: 0.2020\n",
      "Epoch 1/4\n",
      "1500/1500 [==============================] - 41s - loss: 1.8923 - acc: 0.4127 - val_loss: 2.7509 - val_acc: 0.2450\n",
      "Epoch 2/4\n",
      "1500/1500 [==============================] - 30s - loss: 1.4383 - acc: 0.5367 - val_loss: 1.7658 - val_acc: 0.4150\n",
      "Epoch 3/4\n",
      "1500/1500 [==============================] - 29s - loss: 1.2423 - acc: 0.6007 - val_loss: 2.2516 - val_acc: 0.2800\n",
      "Epoch 4/4\n",
      "1500/1500 [==============================] - 28s - loss: 0.9766 - acc: 0.6827 - val_loss: 1.8854 - val_acc: 0.3480\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "gen_t = image.ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=15,\n",
    "    channel_shift_range=20\n",
    ")\n",
    "batches = get_batches(data_path + 'train', gen_t, batch_size=batch_size)\n",
    "\n",
    "model = get_conv_model(train=False)\n",
    "model.optimizer.lr.set_value(1e-4)\n",
    "h = model.fit_generator(\n",
    "    batches, \n",
    "    batches.nb_sample, \n",
    "    nb_epoch=2, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")\n",
    "history.append(h)\n",
    "\n",
    "model.optimizer.lr.set_value(1e-3)\n",
    "h = model.fit_generator(\n",
    "    batches, \n",
    "    batches.nb_sample, \n",
    "    nb_epoch=4, \n",
    "    validation_data=v_batches, \n",
    "    nb_val_samples=v_batches.nb_sample\n",
    ")\n",
    "history.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 38s - loss: 0.9351 - acc: 0.7047 - val_loss: 1.8350 - val_acc: 0.3520\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 28s - loss: 0.8673 - acc: 0.7320 - val_loss: 1.7802 - val_acc: 0.3730\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 29s - loss: 0.8072 - acc: 0.7360 - val_loss: 1.6951 - val_acc: 0.3970\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 29s - loss: 0.7635 - acc: 0.7600 - val_loss: 1.6148 - val_acc: 0.4400\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 31s - loss: 0.7550 - acc: 0.7673 - val_loss: 1.4959 - val_acc: 0.4880\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 38s - loss: 0.7199 - acc: 0.7787 - val_loss: 1.3660 - val_acc: 0.5230\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.6489 - acc: 0.8007 - val_loss: 1.2511 - val_acc: 0.5470\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.6544 - acc: 0.7980 - val_loss: 1.1116 - val_acc: 0.6370\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 30s - loss: 0.6381 - acc: 0.8020 - val_loss: 0.9837 - val_acc: 0.6770\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.6348 - acc: 0.7993 - val_loss: 0.8733 - val_acc: 0.7210\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 33s - loss: 0.5825 - acc: 0.8273 - val_loss: 0.8122 - val_acc: 0.7420\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 28s - loss: 0.5198 - acc: 0.8413 - val_loss: 0.6984 - val_acc: 0.8080\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 28s - loss: 0.5154 - acc: 0.8493 - val_loss: 0.5975 - val_acc: 0.8670\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 28s - loss: 0.5126 - acc: 0.8433 - val_loss: 0.5712 - val_acc: 0.8550\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 31s - loss: 0.4984 - acc: 0.8553 - val_loss: 0.4881 - val_acc: 0.8780\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.5033 - acc: 0.8420 - val_loss: 0.7731 - val_acc: 0.7330\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.4685 - acc: 0.8607 - val_loss: 0.4089 - val_acc: 0.8970\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 28s - loss: 0.4482 - acc: 0.8680 - val_loss: 0.3544 - val_acc: 0.9160\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.4486 - acc: 0.8640 - val_loss: 0.3375 - val_acc: 0.9240\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.4352 - acc: 0.8667 - val_loss: 0.3165 - val_acc: 0.9320\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 30s - loss: 0.4183 - acc: 0.8713 - val_loss: 0.2850 - val_acc: 0.9270\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 30s - loss: 0.4258 - acc: 0.8580 - val_loss: 0.2745 - val_acc: 0.9410\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.4135 - acc: 0.8780 - val_loss: 0.2743 - val_acc: 0.9320\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.3909 - acc: 0.8873 - val_loss: 0.2581 - val_acc: 0.9470\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 28s - loss: 0.3601 - acc: 0.8947 - val_loss: 0.2419 - val_acc: 0.9410\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 30s - loss: 0.3596 - acc: 0.9073 - val_loss: 0.2521 - val_acc: 0.9390\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.3635 - acc: 0.8933 - val_loss: 0.2343 - val_acc: 0.9390\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 29s - loss: 0.3365 - acc: 0.9073 - val_loss: 0.2257 - val_acc: 0.9470\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 30s - loss: 0.3462 - acc: 0.9027 - val_loss: 0.2211 - val_acc: 0.9400\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 30s - loss: 0.3441 - acc: 0.8907 - val_loss: 0.2110 - val_acc: 0.9530\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr.set_value(0.0001)\n",
    "h = model.fit_generator(\n",
    "    batches, batches.nb_sample, \n",
    "    nb_epoch=5, \n",
    "    validation_data=v_batches, nb_val_samples=v_batches.nb_sample)\n",
    "history.append(h)\n",
    "h = model.fit_generator(\n",
    "    batches, batches.nb_sample, \n",
    "    nb_epoch=25, \n",
    "    validation_data=v_batches, nb_val_samples=v_batches.nb_sample)\n",
    "history.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f20929c1d10>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f20929a8210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = []\n",
    "val_acc = []\n",
    "for h in history:\n",
    "    acc += h.history['acc']\n",
    "    val_acc += h.history['val_acc']\n",
    "    \n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(samp_data_path + 'state-farm-cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20424 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Found 20424 images belonging to 10 classes.\n",
      "Found 2000 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n",
      "Found 20424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "t_batches = get_batches(full_data_path + 'train', batch_size=batch_size)\n",
    "v_batches = get_batches(full_data_path + 'valid', batch_size=2*batch_size, shuffle=False)\n",
    "\n",
    "(\n",
    "    val_classes, trn_classes, \n",
    "    val_labels, trn_labels, \n",
    "    val_filenames, filenames,\n",
    "    test_filename\n",
    ") = get_classes(full_data_path)\n",
    "\n",
    "batches = get_batches(full_data_path + 'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20424/20424 [==============================] - 364s - loss: 0.4005 - acc: 0.8806 - val_loss: 0.1674 - val_acc: 0.9505\n",
      "Epoch 2/5\n",
      "20424/20424 [==============================] - 312s - loss: 0.3078 - acc: 0.9095 - val_loss: 0.1163 - val_acc: 0.9720\n",
      "Epoch 3/5\n",
      "20424/20424 [==============================] - 316s - loss: 0.2482 - acc: 0.9271 - val_loss: 0.0927 - val_acc: 0.9795\n",
      "Epoch 4/5\n",
      "20424/20424 [==============================] - 318s - loss: 0.2214 - acc: 0.9367 - val_loss: 0.0833 - val_acc: 0.9835\n",
      "Epoch 5/5\n",
      "20424/20424 [==============================] - 317s - loss: 0.1832 - acc: 0.9478 - val_loss: 0.0882 - val_acc: 0.9795\n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(\n",
    "    batches, batches.nb_sample, \n",
    "    nb_epoch=5, \n",
    "    validation_data=v_batches, nb_val_samples=v_batches.nb_sample\n",
    ")\n",
    "history.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f209ba5b2d0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f209246e190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = []\n",
    "val_acc = []\n",
    "for h in history:\n",
    "    acc += h.history['acc']\n",
    "    val_acc += h.history['val_acc']\n",
    "    \n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(full_data_path + 'state-farm-cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submit\n",
    "\n",
    "Compute test set output and actually submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai import kaggle\n",
    "\n",
    "def submission_df(preds, test_batches, classes):\n",
    "    # construct dataframe of the submission\n",
    "    index = pd.Series(\n",
    "        [f.split('/')[-1] for f in test_batches.filenames],\n",
    "        name='img'\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        preds,\n",
    "        index=index,\n",
    "        columns=classes\n",
    "    )\n",
    "\n",
    "    return df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n",
      "Found 20424 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(\n",
    "    full_data_path + 'test', shuffle=False, batch_size=batch_size * 2,\n",
    "    class_mode=None)\n",
    "train_batches = get_batches(\n",
    "    full_data_path + 'train', shuffle=False, batch_size=batch_size,\n",
    "    class_mode=None)\n",
    "classes = sorted(train_batches.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "preds = model.predict_generator(test_batches, test_batches.nb_sample, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = submission_df(preds, test_batches, classes)\n",
    "df = df.clip(0.05, 0.95)\n",
    "df.to_csv(full_data_path + 'submission.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    'kg',\n",
    "    'submit',\n",
    "    '-u', os.environ['KAGGLE_USERNAME'],\n",
    "    '-p', os.environ['KAGGLE_PASSWORD'],\n",
    "    '-c', 'state-farm-distracted-driver-detection',\n",
    "    full_data_path + 'submission.csv'\n",
    "]\n",
    "\n",
    "subprocess.call(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
